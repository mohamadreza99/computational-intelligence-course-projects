{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIENrm3oOpW0",
    "outputId": "56ef3f7e-2db7-4179-92ce-e68cfd58e61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxrQSAPsPC5d",
    "outputId": "63d01b25-11a3-4372-c778-794dda8edc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/homeWorkDataSet\n"
     ]
    }
   ],
   "source": [
    "cd gdrive/MyDrive/homeWorkDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tHeI1mTBefx"
   },
   "source": [
    "در این نوت بوک سعی شده طبق روند معمول نوت بوک های پایتورچ طراحی صورت پذیرد.\n",
    "\n",
    "هر چند بخش اعظمی از کد به صورت دستی نوشته شده و حاوی تغییرات زیادی است\n",
    "\n",
    "به عنوان مثال از هیچ شبکه ی از پیش آماده ای استفاده نشده و با دیزاین یک شبکه در کلاسی به نام \n",
    "\n",
    "resnet \n",
    "\n",
    "با ارث بری از کلاس پایه شبکه های عصبی در پایتورچ\n",
    " سعی شده تا بهترین نتیجه گرفته شود."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_61WF9UvCKwT"
   },
   "source": [
    "مدل با پارامتر های مختلف آزمایش شده که در انتها سه نمونه از دقت های بدست آمده را مشاهده می کنید.\n",
    "\n",
    "بهترین پارامتر ها در همین نوت بوک حاضر اعمال شده است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPqUDYkqeoow"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMnSXs7m7H2L"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2wtXUeE3jwS"
   },
   "source": [
    "data augmentation to generate more instances from training set\n",
    "\n",
    "data preprocessing and resize all images to a size that is comfortable for gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VHZ6Yu9eomL"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# in homeWorkDataSet Directory\n",
    "data_dir = 'data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=8)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7HPllGm30vy"
   },
   "source": [
    "I have preprocess all the datas and split them to two folders which names is train and val\n",
    "\n",
    "they locates under data directory. if you want to run this notebook, tell me to give access to you.\n",
    "\n",
    "the code I used to stratified sampling 20 percent of data and put them as val set is the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTJAgnwK4xkR"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "# import shutil\n",
    "# import random\n",
    "# val_size = 0.2\n",
    "# val_dir = Path('data/val/')\n",
    "# train_dir = Path('data/train/')\n",
    "# for entry in train_dir.iterdir():\n",
    "#   images = [f for f in entry.iterdir()]\n",
    "#   size = len(images)\n",
    "#   randoms = set()\n",
    "#   for i in range(int(size*val_size)):\n",
    "#     random_image = random.choice(images)\n",
    "#     while random_image in randoms:\n",
    "#       random_image = random.choice(images)\n",
    "#     randoms.add(random_image)\n",
    "#     dest_dir = val_dir/entry.name\n",
    "#     dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     shutil.move(random_image, dest_dir/random_image.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYPpx2N2I8mo",
    "outputId": "0dcdcbdf-fb67-4c0a-9cdf-b91628668453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVTF1W2ieocd"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NJlcVl0eoZ2"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn7mqlfY9M_Z"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, groups=1, bias=False, dilation=1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, groups=1, bias=False, dilation=1)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6EXGMhg9Ukc"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * self.expansion, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwcIbz-6AxwT"
   },
   "source": [
    "I designed my own resnet. the detail of network is in _forward_impl method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxdjdG8L6-Oq"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YddoqptMBIaZ"
   },
   "source": [
    "for better results, I upload the weights of resnet18 to my network, this is an advice from Mr shahverdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86QwwvZL3XQ8",
    "outputId": "6cf964cb-060c-439b-a37b-9470b370e0ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "state_dict = load_state_dict_from_url('https://download.pytorch.org/models/resnet18-5c106cde.pth', progress=True)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiV1JjmheoXd"
   },
   "outputs": [],
   "source": [
    "model_ft = model\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 120)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# fit the parameters with sgd optimizer\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay learning rate by a factor of 0.1 every 7 epochs\n",
    "# use weight decay to avoid overfitting \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioCG7Mt6ygLw",
    "outputId": "c539a5d2-803c-4f8e-a05a-a95948aaa1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.7742 Acc: 0.3734\n",
      "val Loss: 1.0996 Acc: 0.6933\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.6449 Acc: 0.5786\n",
      "val Loss: 0.9013 Acc: 0.7331\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.4491 Acc: 0.6169\n",
      "val Loss: 0.7797 Acc: 0.7642\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.3407 Acc: 0.6403\n",
      "val Loss: 0.7750 Acc: 0.7652\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.2726 Acc: 0.6539\n",
      "val Loss: 0.7997 Acc: 0.7522\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.2243 Acc: 0.6664\n",
      "val Loss: 0.7636 Acc: 0.7660\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.1567 Acc: 0.6839\n",
      "val Loss: 0.7640 Acc: 0.7655\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.0335 Acc: 0.7222\n",
      "val Loss: 0.6482 Acc: 0.8077\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.9869 Acc: 0.7334\n",
      "val Loss: 0.6487 Acc: 0.8084\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.9480 Acc: 0.7457\n",
      "val Loss: 0.6299 Acc: 0.8170\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.9356 Acc: 0.7505\n",
      "val Loss: 0.6310 Acc: 0.8197\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.9347 Acc: 0.7482\n",
      "val Loss: 0.6263 Acc: 0.8139\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.9242 Acc: 0.7524\n",
      "val Loss: 0.6229 Acc: 0.8116\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.9132 Acc: 0.7561\n",
      "val Loss: 0.6187 Acc: 0.8153\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.8952 Acc: 0.7623\n",
      "val Loss: 0.6205 Acc: 0.8156\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.9149 Acc: 0.7571\n",
      "val Loss: 0.6209 Acc: 0.8136\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.8893 Acc: 0.7660\n",
      "val Loss: 0.6166 Acc: 0.8153\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.8969 Acc: 0.7578\n",
      "val Loss: 0.6171 Acc: 0.8161\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.8992 Acc: 0.7622\n",
      "val Loss: 0.6141 Acc: 0.8156\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.8895 Acc: 0.7612\n",
      "val Loss: 0.6198 Acc: 0.8183\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.9039 Acc: 0.7588\n",
      "val Loss: 0.6212 Acc: 0.8139\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.8760 Acc: 0.7708\n",
      "val Loss: 0.6150 Acc: 0.8168\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.8895 Acc: 0.7648\n",
      "val Loss: 0.6151 Acc: 0.8178\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.9054 Acc: 0.7600\n",
      "val Loss: 0.6121 Acc: 0.8190\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.8784 Acc: 0.7661\n",
      "val Loss: 0.6169 Acc: 0.8168\n",
      "\n",
      "Training complete in 52m 37s\n",
      "Best val Acc: 0.819745\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) # batch size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEe6OFtqDD3X"
   },
   "outputs": [],
   "source": [
    "# below train was last about 2 hours and is my best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1V_gxJbeoUp",
    "outputId": "6ef0ca0f-2509-407c-90fe-26565c46545d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 3.0126 Acc: 0.3672\n",
      "val Loss: 1.2289 Acc: 0.7182\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.6569 Acc: 0.6059\n",
      "val Loss: 0.8176 Acc: 0.7883\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.3911 Acc: 0.6453\n",
      "val Loss: 0.6698 Acc: 0.8173\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.2613 Acc: 0.6657\n",
      "val Loss: 0.5930 Acc: 0.8335\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.1863 Acc: 0.6810\n",
      "val Loss: 0.5354 Acc: 0.8459\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.1354 Acc: 0.6947\n",
      "val Loss: 0.4823 Acc: 0.8603\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.0720 Acc: 0.7112\n",
      "val Loss: 0.4286 Acc: 0.8751\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.9978 Acc: 0.7324\n",
      "val Loss: 0.4012 Acc: 0.8872\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.9765 Acc: 0.7421\n",
      "val Loss: 0.3885 Acc: 0.8928\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.9515 Acc: 0.7482\n",
      "val Loss: 0.3787 Acc: 0.8953\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.9503 Acc: 0.7476\n",
      "val Loss: 0.3767 Acc: 0.8960\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.9467 Acc: 0.7483\n",
      "val Loss: 0.3691 Acc: 0.8964\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.9323 Acc: 0.7526\n",
      "val Loss: 0.3618 Acc: 0.8994\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.9442 Acc: 0.7515\n",
      "val Loss: 0.3601 Acc: 0.9010\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.9095 Acc: 0.7603\n",
      "val Loss: 0.3639 Acc: 0.8987\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.9053 Acc: 0.7604\n",
      "val Loss: 0.3559 Acc: 0.9022\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.9212 Acc: 0.7544\n",
      "val Loss: 0.3612 Acc: 0.9005\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.9201 Acc: 0.7556\n",
      "val Loss: 0.3558 Acc: 0.9019\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.9207 Acc: 0.7583\n",
      "val Loss: 0.3572 Acc: 0.9028\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.9158 Acc: 0.7576\n",
      "val Loss: 0.3549 Acc: 0.9019\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.9069 Acc: 0.7615\n",
      "val Loss: 0.3537 Acc: 0.9030\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.9043 Acc: 0.7612\n",
      "val Loss: 0.3559 Acc: 0.9014\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.9203 Acc: 0.7570\n",
      "val Loss: 0.3604 Acc: 0.9006\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.9060 Acc: 0.7587\n",
      "val Loss: 0.3620 Acc: 0.8986\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.9155 Acc: 0.7605\n",
      "val Loss: 0.3515 Acc: 0.9033\n",
      "\n",
      "Training complete in 133m 28s\n",
      "Best val Acc: 0.903304\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) # batch size = 32, my best accuracy on val = 90.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rbqQn_Lrc23",
    "outputId": "ccee5878-59cc-44c8-dfbf-9d76334829e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 3.8615 Acc: 0.2172\n",
      "val Loss: 2.3468 Acc: 0.5371\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.3488 Acc: 0.5177\n",
      "val Loss: 1.4533 Acc: 0.6935\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.7978 Acc: 0.6060\n",
      "val Loss: 1.1080 Acc: 0.7412\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.5422 Acc: 0.6421\n",
      "val Loss: 0.9649 Acc: 0.7615\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.3869 Acc: 0.6640\n",
      "val Loss: 0.8754 Acc: 0.7726\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.2958 Acc: 0.6776\n",
      "val Loss: 0.8051 Acc: 0.7800\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.2200 Acc: 0.6962\n",
      "val Loss: 0.7600 Acc: 0.7881\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.1528 Acc: 0.7143\n",
      "val Loss: 0.7463 Acc: 0.7947\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.1415 Acc: 0.7149\n",
      "val Loss: 0.7461 Acc: 0.7947\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.1257 Acc: 0.7157\n",
      "val Loss: 0.7382 Acc: 0.7972\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.1281 Acc: 0.7197\n",
      "val Loss: 0.7289 Acc: 0.7969\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.1119 Acc: 0.7246\n",
      "val Loss: 0.7312 Acc: 0.8008\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.1107 Acc: 0.7200\n",
      "val Loss: 0.7240 Acc: 0.7991\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.0994 Acc: 0.7233\n",
      "val Loss: 0.7245 Acc: 0.8008\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.1020 Acc: 0.7238\n",
      "val Loss: 0.7271 Acc: 0.8028\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.0901 Acc: 0.7266\n",
      "val Loss: 0.7249 Acc: 0.8033\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.0863 Acc: 0.7283\n",
      "val Loss: 0.7259 Acc: 0.8026\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.0821 Acc: 0.7284\n",
      "val Loss: 0.7250 Acc: 0.8021\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.1057 Acc: 0.7198\n",
      "val Loss: 0.7148 Acc: 0.8016\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.1138 Acc: 0.7227\n",
      "val Loss: 0.7206 Acc: 0.8001\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.0985 Acc: 0.7211\n",
      "val Loss: 0.7219 Acc: 0.8043\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.1078 Acc: 0.7270\n",
      "val Loss: 0.7194 Acc: 0.8013\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.0965 Acc: 0.7251\n",
      "val Loss: 0.7212 Acc: 0.8028\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.1023 Acc: 0.7253\n",
      "val Loss: 0.7202 Acc: 0.8018\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.1015 Acc: 0.7255\n",
      "val Loss: 0.7211 Acc: 0.8028\n",
      "\n",
      "Training complete in 48m 38s\n",
      "Best val Acc: 0.804273\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) # batch size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EqmlVRrcx9"
   },
   "source": [
    "# My best Acc on val is : 90.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "taklif3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
